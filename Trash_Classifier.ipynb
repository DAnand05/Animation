{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOHuO8CjnRQblYD1FfQYPYJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DAnand05/Animation/blob/main/Trash_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lr-astymhA3",
        "outputId": "4267db09-ff0a-4f0d-8a91-a124017bfef3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/trashnet.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lspU2rxmiNw",
        "outputId": "52bc3618-f17b-42e0-94f5-ee97a2697b88"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/trashnet.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/drive/MyDrive/trashnet.zip','r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "HWv__sRgmlXg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Flatten, Dense"
      ],
      "metadata": {
        "id": "gY9G-XRQmoBC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data directories\n",
        "train_dir = \"/content/data/train\"\n",
        "val_dir = \"/content/data/test\"\n",
        "test_dir = \"/content/data/test\"  # Optional for final evaluation\n",
        "\n",
        "# Image size for preprocessing\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "# Data augmentation configuration\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Normalize pixel values\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=20,\n",
        "    fill_mode=\"nearest\"\n",
        ")\n",
        "\n",
        "# Train data generator with augmentation\n",
        "train_datagen = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=32,  # Adjust batch size based on GPU memory\n",
        "    class_mode=\"categorical\"  # Multi-class classification\n",
        ")\n",
        "\n",
        "# Validation data generator (no augmentation)\n",
        "val_datagen = datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\"\n",
        ")\n",
        "\n",
        "# Pre-trained VGG16 model (include weights='imagenet')\n",
        "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(img_width, img_height, 3))\n",
        "base_model.trainable = False  # Freeze base model layers\n",
        "\n",
        "# Add custom classification layers\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation=\"relu\")(x)  # Experiment with different neuron numbers\n",
        "predictions = Dense(6, activation=\"softmax\")(x)  # Output layer for 6 trash classes\n",
        "\n",
        "# Create the final model\n",
        "model = keras.Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Model compilation (adjust learning rate, optimizer based on hyperparameter tuning)\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "              metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMPM6qICmt-B",
        "outputId": "c02f4090-983b-4359-e718-3ef58c66fe2f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2019 images belonging to 6 classes.\n",
            "Found 508 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n",
        "history = model.fit(\n",
        "    train_datagen,\n",
        "    steps_per_epoch=len(train_datagen),  # Adjust based on training data size\n",
        "    epochs=20,  # Adjust epochs based on validation results\n",
        "    validation_data=val_datagen,\n",
        "    validation_steps=len(val_datagen)  # Adjust based on validation data size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qev_4hVYnp6j",
        "outputId": "2c73d33e-32b7-4c48-a238-f02f89db8b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "17/64 [======>.......................] - ETA: 15:20 - loss: 1.7015 - accuracy: 0.3825"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation on test set (optional)\n",
        "if test_dir:\n",
        "    test_datagen = datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=32,\n",
        "        class_mode=\"categorical\"\n",
        "    )\n",
        "    test_loss, test_acc = model.evaluate(test_datagen)\n",
        "    print(\"Test accuracy:\", test_acc)\n",
        "\n",
        "# Save the model for future use (optional)\n",
        "model.save(\"trash_classifier.h5\")\n",
        "\n",
        "# Hyperparameter tuning (optional)\n",
        "# You can use techniques like grid search or random search to find optimal hyperparameters.\n",
        "# Here's a basic example with grid search:\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    \"learning_rate\": [0.0001, 0.001, 0.01],\n",
        "    \"optimizer\": [keras.optimizers.Adam, keras.optimizers.SGD],\n",
        "    \"epochs\": [10, 20, 30]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(model, param_grid, cv=3)  # Adjust cv (cross-validation) folds\n",
        "grid_search.fit(train_datagen)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Evaluate the best model on test set (optional)\n",
        "if test_dir:\n",
        "    test_loss, test_acc = best_model.evaluate(test_datagen)\n",
        "    print(\"Test accuracy with best hyperparameters:\", test_acc)\n",
        "\n",
        "# Further considerations\n",
        "* Explore other CNN architectures like ResNet or EfficientNet for potentially better performance.\n",
        "* Consider class imbalance handling techniques (oversampling, undersampling) if applicable.\n",
        "* Visualize training curves (loss, accuracy) to monitor model learning progress.\n",
        "* Experiment with different data augmentation techniques and parameters.\n",
        "* Use techniques like early stopping to prevent overfitting."
      ],
      "metadata": {
        "id": "VvJEw77qm_r0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}